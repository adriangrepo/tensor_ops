{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook covers some of the key operations used in pytorch. We start with a quick oversion of axues (both numpy and pytorch use same representation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Axes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2D matrices"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For both numpy and pytorch, axis 0 = row, 1 = column\n",
    "\n",
    "Note how when we specify axis=0 for sum, we are collapsing along that (row) axis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([4, 5])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum([[1, 0], [3, 5]], axis=0) #->[1+3, 0+5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we flatten on colums we remove a column dimension - (ie we dont sum along columns :-) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 8])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum([[1, 0], [3, 5]], axis=1) #->[1+0, 3+5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3D arrays / tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.random.randint(10, size=(2,2,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[[9, 4],\n",
       "         [5, 4]],\n",
       " \n",
       "        [[4, 3],\n",
       "         [9, 0]]]),\n",
       " (2, 2, 2))"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a, a.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "axis 0, this referes to arrays in the outside bracket [  [[]],[[]]  ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[9, 4],\n",
       "        [5, 4]]),\n",
       " array([[4, 3],\n",
       "        [9, 0]]))"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a[0], a[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "axis 1 refers to elements in each of the axis 0 items"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([9, 4]), array([5, 4]), array([4, 3]), array([9, 0]))"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a[0][0], a[0][1], a[1][0], a[1][1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "axis 2 refers to the elements in each of axis 1 items \n",
    "\n",
    "ie we gradually peel away brackets as we go deeper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9, 4, 5, 4)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a[0][0][0], a[0][0][1], a[0][1][0],  a[0][1][1] #etc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Flatten along axis 0 - similar to when we flatten on axis 0 in 2D. This reduces our array to 2 dimensions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "b = np.sum(a, axis=0) #-> [[9+4, 4+3],[5+9, 4+0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[13,  7],\n",
       "        [14,  4]]),\n",
       " (2, 2))"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b, b.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[14,  8],\n",
       "       [13,  3]])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(a, axis=1) #->[[9+5, 4+4],[4+9, 3+0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[13,  9],\n",
       "       [ 7,  9]])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(a, axis=2) #-> [[9+4, 5+4], [4+3, 9+0]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### argmax\n",
    "\n",
    "Returns the indices of the maximum value of all elements in the input tensor.\n",
    "\n",
    "This is the second value returned by torch.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 2.0149,  1.0420, -1.3816],\n",
       "        [-1.0265, -0.5212, -0.7570],\n",
       "        [-0.5141,  0.5674,  0.1039],\n",
       "        [-0.1549, -0.3003, -0.1086]])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = torch.randn(4, 3)\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.argmax(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.6022, 1.1465, 0.3250, 1.0555])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b = torch.randn(4)\n",
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.argmax(b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### max\n",
    "\n",
    "##### torch.max(input)\n",
    "\n",
    "Returns the maximum value of all elements in the input tensor.\n",
    "\n",
    "##### torch.max(input, dim, keepdim=False, out=None) \n",
    "\n",
    "Returns a namedtuple (values, indices) where values is the maximum value of each row of the input tensor in the given dimension dim. And indices is the index location of each maximum value found (argmax).\n",
    "\n",
    "If keepdim is True, the output tensors are of the same size as input except in the dimension dim where they are of size 1. Otherwise, dim is squeezed (see torch.squeeze()), resulting in the output tensors having 1 fewer dimension than input."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(2.0149)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.max(a)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "dim 0 ->  max over all rows (i.e. for each column): "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.return_types.max(\n",
       "values=tensor([2.0149, 1.0420, 0.1039]),\n",
       "indices=tensor([0, 0, 2]))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.max(a, 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "dim 1 -> max over all columns (i.e. for each row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.return_types.max(\n",
       "values=tensor([ 2.0149, -0.5212,  0.5674, -0.1086]),\n",
       "indices=tensor([0, 1, 1, 2]))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.max(a, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### view\n",
    "\n",
    "Returns a new tensor with the same data as the self tensor but of a different shape.\n",
    "\n",
    "The returned tensor shares the same data and must have the same number of elements, but may have a different size. For a tensor to be viewed, the new view size must be compatible with its original size and stride, i.e., each new view dimension must either be a subspace of an original dimension, or only span across original dimensions d,d+1,…,d+kd, d+1, \\dots, d+kd,d+1,…,d+k that satisfy the following contiguity-like condition that ∀i=0,…,k−1\\forall i = 0, \\dots, k-1∀i=0,…,k−1 \n",
    "\n",
    "stride[i]=stride[i+1]×size[i+1]\\text{stride}[i] = \\text{stride}[i+1] \\times \\text{size}[i+1]stride[i]=stride[i+1]×size[i+1]\n",
    "\n",
    "Otherwise, contiguous() needs to be called before the tensor can be viewed. See also: reshape(), which returns a view if the shapes are compatible, and copies (equivalent to calling contiguous()) otherwise.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 3])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.randn(4, 3)\n",
    "x.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([12])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = x.view(12)\n",
    "y.size()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Without a -1 need to get dimension correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#y = x.view(10)\n",
    "#y.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([6, 2])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z = x.view(-1, 2)  # the size -1 is inferred from other dimensions\n",
    "z.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([6, 2])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w = x.view(6, -1)  # the size -1 is inferred from other dimensions\n",
    "w.size()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### sum"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### torch.sum(input, dtype=None)\n",
    "    \n",
    "Returns the sum of all elements in the input tensor.\n",
    "\n",
    "#### torch.sum(input, dim, keepdim=False, dtype=None) \n",
    "\n",
    "Returns the sum of each row of the input tensor in the given dimension dim. If dim is a list of dimensions, reduce over all of them.\n",
    "\n",
    "If keepdim is True, the output tensor is of the same size as input except in the dimension(s) dim where it is of size 1. Otherwise, dim is squeezed (see torch.squeeze()), resulting in the output tensor having 1 (or len(dim)) fewer dimension(s).\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 1.7224, -1.3243,  0.3586]])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = torch.randn(1, 3)\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.7567)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.sum(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-1.1065,  0.5816,  1.1932],\n",
       "        [ 0.3565,  1.9991,  0.2112],\n",
       "        [ 0.9671, -0.3203, -1.0331],\n",
       "        [-2.0222, -0.4018, -1.8219]])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = torch.randn(4, 3)\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0.6683,  2.5669, -0.3863, -4.2459])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#sum over all columns (i.e. for each row)\n",
    "torch.sum(a, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### mean\n",
    "\n",
    "#### torch.mean(input)\n",
    "\n",
    "Returns the mean value of all elements in the input tensor.\n",
    "\n",
    "#### torch.mean(input, dim, keepdim=False, out=None) \n",
    "\n",
    "Returns the mean value of each row of the input tensor in the given dimension dim. If dim is a list of dimensions, reduce over all of them.\n",
    "\n",
    "If keepdim is True, the output tensor is of the same size as input except in the dimension(s) dim where it is of size 1. Otherwise, dim is squeezed (see torch.squeeze()), resulting in the output tensor having 1 (or len(dim)) fewer dimension(s)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 1.1041, -0.4993,  1.8628],\n",
       "        [-0.6035,  0.6425, -1.3106],\n",
       "        [-0.6543, -0.4198, -0.4286],\n",
       "        [ 2.0873,  0.4965, -0.7824]])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = torch.randn(4, 3)\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.1245)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "dim = 1 -> over all columns (for each row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0.8225, -0.4239, -0.5009,  0.6004])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.mean(a, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.8225],\n",
       "        [-0.4239],\n",
       "        [-0.5009],\n",
       "        [ 0.6004]])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.mean(a, 1, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0.4834,  0.0549, -0.1647])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.mean(a, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-0.5509, -0.8295],\n",
       "         [-0.1816,  0.8299],\n",
       "         [-0.7890,  0.0698]],\n",
       "\n",
       "        [[-0.3103, -1.1878],\n",
       "         [-1.2422, -1.8429],\n",
       "         [-0.8061, -0.2843]],\n",
       "\n",
       "        [[ 0.3603, -1.9474],\n",
       "         [-0.2442, -0.8164],\n",
       "         [ 1.2880,  0.1848]],\n",
       "\n",
       "        [[-0.2814, -1.2271],\n",
       "         [ 0.2662,  0.3517],\n",
       "         [ 0.0496,  0.0306]]])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = torch.randn(4, 3, 2)\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-1.9556e-01, -1.2980e+00],\n",
       "        [-3.5046e-01, -3.6942e-01],\n",
       "        [-6.4377e-02,  2.2051e-04]])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b=torch.mean(a,0)\n",
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 2])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.5072,  0.0234],\n",
       "        [-0.7862, -1.1050],\n",
       "        [ 0.4680, -0.8597],\n",
       "        [ 0.0115, -0.2816]])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c=torch.mean(a,1)\n",
    "c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 2])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random\n",
    "\n",
    "Returns a tensor filled with random numbers from a normal distribution with mean 0 and variance 1 (also called the standard normal distribution).\n",
    "\n",
    "torch.randn(*size, out=None, dtype=None, layout=torch.strided, device=None, requires_grad=False) → Tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.5951,  1.4342, -1.2732],\n",
       "        [ 0.1727,  1.2753, -0.8301]])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.randn(2, 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Flatten\n",
    "\n",
    "Flattens a contiguous range of dims in a tensor.\n",
    "\n",
    "torch.flatten(input, start_dim=0, end_dim=-1) → Tensor\n",
    "\n",
    "\n",
    "\n",
    "        input (Tensor) – the input tensor.\n",
    "\n",
    "        start_dim (python:int) – the first dim to flatten\n",
    "\n",
    "        end_dim (python:int) – the last dim to flatten\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = torch.tensor([[[1, 2],\n",
    "                    [3, 4]],\n",
    "                    [[5, 6],\n",
    "                    [7, 8]]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 2, 2])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1, 2, 3, 4, 5, 6, 7, 8])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.flatten(t)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can use the start_dim to flatten a single dimension - hany when you have a dimension of 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1, 2, 3, 4],\n",
       "        [5, 6, 7, 8]])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.flatten(t, start_dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 1, 3, 3])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = torch.randn(4, 1, 3, 3)\n",
    "a.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 3, 3])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b = torch.flatten(a, start_dim=1, end_dim=2)\n",
    "b.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 1.0668,  0.6964, -2.1182],\n",
       "         [-1.0142,  0.5931, -1.3457],\n",
       "         [ 0.7723, -0.5258,  1.3341]],\n",
       "\n",
       "        [[-0.1119,  1.6734, -1.6325],\n",
       "         [ 0.5137, -0.7176, -0.5566],\n",
       "         [-0.5263, -0.3947,  1.7352]],\n",
       "\n",
       "        [[-1.3183,  1.1556,  0.5092],\n",
       "         [-1.2826, -0.4203, -1.0321],\n",
       "         [-0.3116, -0.1535, -0.6810]],\n",
       "\n",
       "        [[-0.8669,  0.4939,  1.1409],\n",
       "         [ 0.2214,  0.0935, -0.2618],\n",
       "         [ 0.4363, -0.9791,  1.2344]]])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[ 1.0668,  0.6964, -2.1182],\n",
       "          [-1.0142,  0.5931, -1.3457],\n",
       "          [ 0.7723, -0.5258,  1.3341]]],\n",
       "\n",
       "\n",
       "        [[[-0.1119,  1.6734, -1.6325],\n",
       "          [ 0.5137, -0.7176, -0.5566],\n",
       "          [-0.5263, -0.3947,  1.7352]]],\n",
       "\n",
       "\n",
       "        [[[-1.3183,  1.1556,  0.5092],\n",
       "          [-1.2826, -0.4203, -1.0321],\n",
       "          [-0.3116, -0.1535, -0.6810]]],\n",
       "\n",
       "\n",
       "        [[[-0.8669,  0.4939,  1.1409],\n",
       "          [ 0.2214,  0.0935, -0.2618],\n",
       "          [ 0.4363, -0.9791,  1.2344]]]])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Eye\n",
    "\n",
    "Returns a 2-D tensor with ones on the diagonal and zeros elsewhere.\n",
    "\n",
    "\n",
    "\n",
    "        n (python:int) – the number of rows\n",
    "\n",
    "        m (python:int, optional) – the number of columns with default being n\n",
    "\n",
    "        out (Tensor, optional) – the output tensor.\n",
    "\n",
    "        dtype (torch.dtype, optional) – the desired data type of returned tensor. Default: if None, uses a global default (see torch.set_default_tensor_type()).\n",
    "\n",
    "        layout (torch.layout, optional) – the desired layout of returned Tensor. Default: torch.strided.\n",
    "\n",
    "        device (torch.device, optional) – the desired device of returned tensor. Default: if None, uses the current device for the default tensor type (see torch.set_default_tensor_type()). device will be the CPU for CPU tensor types and the current CUDA device for CUDA tensor types.\n",
    "\n",
    "        requires_grad (bool, optional) – If autograd should record operations on the returned tensor. Default: False.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 0., 0.],\n",
       "        [0., 1., 0.],\n",
       "        [0., 0., 1.]])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.eye(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Range\n",
    "\n",
    "Returns a 1-D tensor of size ⌈(end−start) / step⌉ with values from the interval (start, end) taken with common difference step beginning from start.\n",
    "\n",
    "torch.arange(start=0, end, step=1, out=None, dtype=None, layout=torch.strided, device=None, requires_grad=False) → Tensor\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0, 1, 2, 3, 4])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.arange(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1.0000, 1.5000, 2.0000])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.arange(1, 2.5, 0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Einsum\n",
    "\n",
    "after https://stackoverflow.com/questions/55894693/understanding-pytorch-einsum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "vec=torch.tensor([0, 1, 2, 3])\n",
    "\n",
    "aten=torch.tensor([[11, 12, 13, 14],\n",
    "        [21, 22, 23, 24],\n",
    "        [31, 32, 33, 34],\n",
    "        [41, 42, 43, 44]])\n",
    "\n",
    "bten=torch.tensor([[1, 1, 1, 1],\n",
    "        [2, 2, 2, 2],\n",
    "        [3, 3, 3, 3],\n",
    "        [4, 4, 4, 4]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1) Matrix multiplication\n",
    "\n",
    "PyTorch: torch.matmul(aten, bten) ; aten.mm(bten)\n",
    "\n",
    "NumPy : np.einsum(\"ij, jk -> ik\", arr1, arr2) \n",
    "\n",
    "#### Dot Product"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[130, 130, 130, 130],\n",
       "        [230, 230, 230, 230],\n",
       "        [330, 330, 330, 330],\n",
       "        [430, 430, 430, 430]])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.einsum('ij, jk -> ik', aten, bten)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 11,  12,  13,  14],\n",
       "        [ 42,  44,  46,  48],\n",
       "        [ 93,  96,  99, 102],\n",
       "        [164, 168, 172, 176]])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#### Elementwise multiplication\n",
    "\n",
    "torch.einsum('ij, ij -> ij', aten, bten)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2) Extract elements along the main-diagonal\n",
    "\n",
    "PyTorch: torch.diag(aten)\n",
    "\n",
    "NumPy : np.einsum(\"ii -> i\", arr) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([11, 22, 33, 44])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.einsum('ii -> i', aten)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3) Hadamard product (i.e. element-wise product of two tensors)\n",
    "\n",
    "PyTorch: aten * bten\n",
    "    \n",
    "NumPy : np.einsum(\"ij, ij -> ij\", arr1, arr2) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 11,  12,  13,  14],\n",
       "        [ 42,  44,  46,  48],\n",
       "        [ 93,  96,  99, 102],\n",
       "        [164, 168, 172, 176]])"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.einsum('ij, ij -> ij', aten, bten)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4) Element-wise squaring\n",
    "\n",
    "PyTorch: aten ** 2\n",
    "    \n",
    "NumPy : np.einsum(\"ij, ij -> ij\", arr, arr) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 121,  144,  169,  196],\n",
       "        [ 441,  484,  529,  576],\n",
       "        [ 961, 1024, 1089, 1156],\n",
       "        [1681, 1764, 1849, 1936]])"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.einsum('ij, ij -> ij', aten, aten)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "General: Element-wise nth power can be implemented by repeating the subscript string and tensor n times. For e.g., computing element-wise 4th power of a tensor can be done using:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[  14641,   20736,   28561,   38416],\n",
       "        [ 194481,  234256,  279841,  331776],\n",
       "        [ 923521, 1048576, 1185921, 1336336],\n",
       "        [2825761, 3111696, 3418801, 3748096]])"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.einsum('ij, ij, ij, ij -> ij', aten, aten, aten, aten)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5) Trace (i.e. sum of main-diagonal elements)\n",
    "\n",
    "PyTorch: torch.trace(aten)\n",
    "NumPy einsum: np.einsum(\"ii -> \", arr) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(110)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.einsum('ii -> ', aten)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6) Matrix transpose\n",
    "\n",
    "PyTorch: torch.transpose(aten, 1, 0)\n",
    "    \n",
    "NumPy einsum: np.einsum(\"ij -> ji\", arr) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[11, 21, 31, 41],\n",
       "        [12, 22, 32, 42],\n",
       "        [13, 23, 33, 43],\n",
       "        [14, 24, 34, 44]])"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.einsum('ij -> ji', aten)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "7) Outer Product (of vectors)\n",
    "\n",
    "PyTorch: torch.ger(vec, vec)\n",
    "\n",
    "NumPy einsum: np.einsum(\"i, j -> ij\", vec, vec) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0, 0, 0, 0],\n",
       "        [0, 1, 2, 3],\n",
       "        [0, 2, 4, 6],\n",
       "        [0, 3, 6, 9]])"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.einsum('i, j -> ij', vec, vec)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "8) Inner Product (of vectors) PyTorch: torch.dot(vec1, vec2)\n",
    "\n",
    "NumPy einsum: np.einsum(\"i, i -> \", vec1, vec2) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(14)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.einsum('i, i -> ', vec, vec)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "9) Sum along axis 0\n",
    "\n",
    "PyTorch: torch.sum(aten, 0)\n",
    "NumPy einsum: np.einsum(\"ij -> j\", arr) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([104, 108, 112, 116])"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.einsum('ij -> j', aten)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "10) Sum along axis 1\n",
    "\n",
    "PyTorch: torch.sum(aten, 1)\n",
    "    \n",
    "NumPy einsum: np.einsum(\"ij -> i\", arr) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 50,  90, 130, 170])"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.einsum('ij -> i', aten)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "11) Batch Matrix Multiplication\n",
    "\n",
    "PyTorch: torch.bmm(batch_tensor_1, batch_tensor_2)\n",
    "    \n",
    "NumPy : np.einsum(\"bij, bjk -> bik\", batch_tensor_1, batch_tensor_2) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[  20,   23,   26,   29],\n",
       "         [  56,   68,   80,   92],\n",
       "         [  92,  113,  134,  155],\n",
       "         [ 128,  158,  188,  218]],\n",
       "\n",
       "        [[ 632,  671,  710,  749],\n",
       "         [ 776,  824,  872,  920],\n",
       "         [ 920,  977, 1034, 1091],\n",
       "         [1064, 1130, 1196, 1262]]])"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_tensor_1 = torch.arange(2 * 4 * 3).reshape(2, 4, 3)\n",
    "batch_tensor_2 = torch.arange(2 * 3 * 4).reshape(2, 3, 4) \n",
    "\n",
    "torch.bmm(batch_tensor_1, batch_tensor_2) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 4, 4])"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# sanity check with the shapes\n",
    "torch.bmm(batch_tensor_1, batch_tensor_2).shape "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[  20,   23,   26,   29],\n",
       "         [  56,   68,   80,   92],\n",
       "         [  92,  113,  134,  155],\n",
       "         [ 128,  158,  188,  218]],\n",
       "\n",
       "        [[ 632,  671,  710,  749],\n",
       "         [ 776,  824,  872,  920],\n",
       "         [ 920,  977, 1034, 1091],\n",
       "         [1064, 1130, 1196, 1262]]])"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# batch matrix multiply using einsum\n",
    "torch.einsum(\"bij, bjk -> bik\", batch_tensor_1, batch_tensor_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 4, 4])"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# sanity check with the shapes\n",
    "torch.einsum(\"bij, bjk -> bik\", batch_tensor_1, batch_tensor_2).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "12) Sum along axis 2\n",
    "\n",
    "PyTorch: torch.sum(batch_ten, 2)\n",
    "    \n",
    "NumPy einsum: np.einsum(\"ijk -> ij\", arr3D) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 3, 12, 21, 30],\n",
       "        [39, 48, 57, 66]])"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.einsum(\"ijk -> ij\", batch_tensor_1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "13) Sum all the elements in an nD tensor\n",
    "\n",
    "PyTorch: torch.sum(batch_ten)\n",
    "    \n",
    "NumPy einsum: np.einsum(\"ijk -> \", arr3D) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(276)"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.einsum(\"ijk -> \", batch_tensor_1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "14) Sum over multiple axes (i.e. marginalization)\n",
    "\n",
    "PyTorch: torch.sum(arr, dim=(dim0, dim1, dim2, dim3, dim4, dim6, dim7))\n",
    "    \n",
    "NumPy: np.einsum(\"ijklmnop -> n\", nDarr) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 5, 4, 6, 8, 2, 7, 9])"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 8D tensor\n",
    "nDten = torch.randn((3,5,4,6,8,2,7,9))\n",
    "nDten.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-111.1110, -263.9169])"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# marginalize out dimension 5 (i.e. \"n\" here)\n",
    "esum = torch.einsum(\"ijklmnop -> n\", nDten)\n",
    "esum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# marginalize out axis 5 (i.e. sum over rest of the axes)\n",
    "tsum = torch.sum(nDten, dim=(0, 1, 2, 3, 4, 6, 7))\n",
    "\n",
    "torch.allclose(tsum, esum)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "15) Double Dot Products (same as: torch.sum(hadamard-product) cf. 3)\n",
    "\n",
    "PyTorch: torch.sum(aten * bten)\n",
    "    \n",
    "NumPy : np.einsum(\"ij, ij -> \", arr1, arr2) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1300)"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.einsum(\"ij, ij -> \", aten, bten)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Numpy Elipsis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy import arange\n",
    "a = arange(16).reshape(2,2,2,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[[ 0,  1],\n",
       "         [ 2,  3]],\n",
       "\n",
       "        [[ 4,  5],\n",
       "         [ 6,  7]]],\n",
       "\n",
       "\n",
       "       [[[ 8,  9],\n",
       "         [10, 11]],\n",
       "\n",
       "        [[12, 13],\n",
       "         [14, 15]]]])"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0,  2,  4,  6,  8, 10, 12, 14])"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a[..., 0].flatten()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Equivalent to:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0,  2,  4,  6,  8, 10, 12, 14])"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a[:,:,:,0].flatten()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Expand size of tensor along non singleton dimension\n",
    "\n",
    "eg extend dim 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 1, 2, 2])"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cuda0 = torch.device('cuda:0')\n",
    "a=torch.ones([2, 1, 2, 2]).to(cuda0)\n",
    "a.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[1., 1.],\n",
       "          [1., 1.]]],\n",
       "\n",
       "\n",
       "        [[[1., 1.],\n",
       "          [1., 1.]]]], device='cuda:0')"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "out = torch.cat([a, torch.zeros(2,1,1,2).to(cuda0)], 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 1, 3, 2])"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[1., 1.],\n",
       "          [1., 1.],\n",
       "          [0., 0.]]],\n",
       "\n",
       "\n",
       "        [[[1., 1.],\n",
       "          [1., 1.],\n",
       "          [0., 0.]]]], device='cuda:0')"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "cuda0 = torch.device('cuda:0')\n",
    "a = torch.randn((2,3), device=cuda0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda', index=0)"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "b=torch.zeros(2,4).to(a.device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda', index=0)"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b.device"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scatter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Writes all values from the tensor src into self at the indices specified in the index tensor. For each value in src, its output index is specified by its index in src for dimension != dim and by the corresponding value in index for dimension = dim.\n",
    "\n",
    "For a 3-D tensor, self is updated as:\n",
    "    \n",
    "<pre>\n",
    "self[index[i][j][k]][j][k] = src[i][j][k]  # if dim == 0\n",
    "self[i][index[i][j][k]][k] = src[i][j][k]  # if dim == 1\n",
    "self[i][j][index[i][j][k]] = src[i][j][k]  # if dim == 2\n",
    "</pre>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.rand(2, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.4183, 0.0121, 0.0719, 0.2705, 0.7525],\n",
       "        [0.1310, 0.4384, 0.3306, 0.8629, 0.6674]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = torch.zeros(3, 5)\n",
    "scatter_pattern = torch.tensor([[0, 1, 2, 0, 0], [2, 0, 0, 1, 2]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.4183, 0.4384, 0.3306, 0.2705, 0.7525],\n",
       "        [0.0000, 0.0121, 0.0000, 0.8629, 0.0000],\n",
       "        [0.1310, 0.0000, 0.0719, 0.0000, 0.6674]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.scatter_(0, scatter_pattern, x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The scatter says “send the elements of x to the following indices in torch.zeros, according to ROW-WISE (dim 0)”. \n",
    "\n",
    "i.e. for each element in the original x tensor, we specify a row index (0, 1 or 2) to send it to in the tensor we are scattering into (y)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Permute\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 3, 5])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.randn(2, 3, 5)\n",
    "x.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([5, 2, 3])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.permute(2, 0, 1).size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
